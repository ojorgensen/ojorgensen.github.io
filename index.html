---
layout: home
title: Ole Jorgensen
---

<div class="home">
  <h2> <b> Overview of me: </b> </h2>
  
  <figure>
  <img src="/img/OleFace.jpg" alt="OleFace" style="width:200px;height:200px;"/>
    <figcaption><i> This is me!</i> </figcaption>
</figure>

<p> Hello! My name is Ole, and I am an AI Safety researcher focussing on language model evaluations and interpretability. I recently completed an MSc in Artificial Intelligence from Imperial College London, and previously received an MMath in Mathematics from the University of St Andrews.</p>
<p> I am involved with the AI Safety and Effective Altruism Communities.</p>

  
  <h2> <b> What I'm Working on: </b> </h2>
  <p>I have just published a paper on evaluating large language models, alongside my group from AI Safety Camp! We investigated the self-consistency of various OpenAI models under ambiguity, using the novel setting of integer sequences. This will be published in the BlackboxNLP workshop at EMNLP 2023, the arxiv version is <a href="https://arxiv.org/abs/2310.13439"> here</a>.</p>

  <p>I completed my Dissertation on investigating latent spaces of transformer models. My supervisors were <a href="https://www.doc.ic.ac.uk/~mpsha/">Murray Shanahan</a>, <a href="https://dylancope.com/">Dylan Cope</a>, and <a href="https://nandischoots.com/">Nandi Schoots</a>, who I have all enjoyed working with immensely.
    Specifically we investigated when transformer models represent features geometrically, and how this can be used to better control models (such as via <a href="https://www.lesswrong.com/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector">activation additions</a> and feature detection).
    You can see my Dissertation <a href="assets/pdfs/Imperial_Dissertation.pdf">here</a>. We are currently working on extending the experiments to Llama models, and will be submitting to a conference in the near future.
    In general I am interested in utilising an improved understanding of model activations to better control language models.
  </p>
  

</div>
